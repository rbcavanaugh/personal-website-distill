[
  {
    "path": "posts/2020-10-15-clinical-implementation-discourse/",
    "title": "Simpler tools for clinical implementation of discourse analysis",
    "description": "Analyzing dicourse production is increasingly the focus of clinical research but time consuming to implement in clinical pratice. This post discusses the use of interactive web-apps to quickly analyze orthographically trascribed discourse samples",
    "author": [
      {
        "name": "Rob Cavanaugh",
        "url": {}
      }
    ],
    "date": "2020-10-15",
    "categories": [
      "discourse",
      "clinical focus"
    ],
    "contents": "\nPeople with aphasia identify everyday communication as one of the highest priorities for treatment.1 One way of estimating everyday communication skills in clinical settings is discourse analysis. For example, people with aphasia are provided with one or more pictures and asked to describe the picture(s) or tell a story. However, analyzing these discourse samples requires time-intensive transcription, coding, and knowledge of software such as CLAN.2 For clinicians with limited time and ambitious productivity requirements, discourse analysis (as currently used by aphasia researchers) is not often feasible. In my experience in outpatient practice, 10 minutes scoring assessments (in addition to what I could score during the evaluation) while writing up an evaluation was a reasonable goal on a normal day.\nOne solution to this challenge is to minimize the time required for discourse analysis. For example, main concept analysis and core lexicon analysis3 are methods of measuring discourse without the need for precise transcription or discourse coding. Recently, Cunningham and Haley4 analyzed the use of two metrics for lexical diversity - a discourse measure that is thought to capture word retrieval skills in connected speech.5 What I find particularly interesting about these two metrics - the word information measure (WIM) and the moving average type-token ratio (MATTR) - is that they were analyzed using only orthographic transcriptions. Consequently, they don’t require discourse coding required by CLAN. Instead they can be calculated using R.\nLast spring, I worked on several projects where I built several interactive shiny apps6 using R so that our team and collaborators could better understand complex data by interacting with it. As a proof of concept, last month I implemented the WIM and MATTR lexical diversity measures in a shiny app to demonstrate how straightforward it can be to provide a simple interface for these measures for clinicians to use. That proof-of-concept app is below (and here). The R code for the app is here. Hopefully, it will be refined with instructions and norms as they come out. I also hope to incorporate an easy interface for main concept analysis and core lexicon in the future.\n\n\nWallace SJ, Worrall L, Rose T, et al. Which outcomes are most important to people with aphasia and their families? an international nominal group technique study framed within the ICF. Disabil Rehabil. 2017;39(14):1364–1379. doi:10.1080/09638288.2016.1194899\nMacWhinney, B. (2000). The CHILDES Project: Tools for analyzing talk. Transcription format and programs (Vol. 1). Psychology Press.\nDalton, S. G., & Richardson, J. D. (2015). Core-lexicon and main-concept production during picture-sequence description in adults without brain damage and adults with aphasia. American Journal of Speech-Language Pathology, 24(4), S923–S938.\nCunningham, K. T., & Haley, K. L. (2020). Measuring Lexical Diversity for Discourse Analysis in Aphasia: Moving-Average Type–Token Ratio and Word Information Measure. Journal of Speech, Language, and Hearing Research, 63(3), 710-721.\nFergadiotis, G., Wright, H. H., & West, T. M. (2013). Measuring lexical diversity in narrative discourse of people with aphasia. American Journal of Speech-Language Pathology.\nhttps://mastering-shiny.org/\n\n\n\n",
    "preview": "posts/2020-10-15-clinical-implementation-discourse/preview_wim.jpg",
    "last_modified": "2020-12-28T09:54:30-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-14-effect-sizes-in-single-subject-designs/",
    "title": "Effect Sizes in single-subject designs",
    "description": "Effect sizes are a critical outcome in single-case design research, but choosing the appropriate effect size for a given study can be challenging.",
    "author": [
      {
        "name": "Rob Cavanaugh",
        "url": {}
      }
    ],
    "date": "2020-09-14",
    "categories": [
      "stats",
      "treatment"
    ],
    "contents": "\n\n\n\n\n\n\nPeople with aphasia respond in very different way to treatment. Changes can be immediate or delayed, fast or slow. Some people don’t benefit at all. Measuring how much people with aphasia benefit from a treatment is important for justifying clinical services and accurately modeling predictors of treatment outcomes\nIn A Systematic Appraisal of Effect Sizes in Aphasia Single-Case Design via Simulation, we simulated data for 100 hypothetical people with aphasia who received a naming treatment in a multiple-baseline design. Then we compared different effect size measures that have been used in the aphasia single-case design literature. spoiler: they’re not all the same.\n Read more here\n\n\n\n\n\n\n",
    "preview": "posts/2020-09-14-effect-sizes-in-single-subject-designs/effect-sizes-in-single-subject-designs_files/figure-html5/plot-1.png",
    "last_modified": "2020-12-28T09:55:04-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
